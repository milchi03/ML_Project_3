{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic Classifier as benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this exercise is to get a feeling and understanding on the importance of\n",
    "representation and extraction of information from complex media content, in this case images or\n",
    "text. You will thus get some datasets that have an image classification target.  \n",
    "\n",
    "(1) In the first step, you shall try to find a good classifier with „traditional“ feature extraction\n",
    "methods. Thus, pick one feature extractor based on e.g. Bag Of Words, or n-grams, or similar\n",
    "You shall evaluate them on two shallow algorithms, optimising the parameter settings to see what\n",
    "performance you can achieve, to have a baseline for the subsequent steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.DataFrame({\n",
    "    'iid': ['AA101', 'BB202', 'CC303', 'DD404', 'EE505', 'FF606', 'GG707', 'HH808', 'II909', 'JJ010'],\n",
    "    'title': [\n",
    "        'Government announces new economic policies to boost growth',\n",
    "        'Scientists discover new species in the Amazon rainforest',\n",
    "        'Major cyberattack disrupts banking systems across Europe',\n",
    "        'Famous actor donates millions to climate change research',\n",
    "        'Experts warn about rising sea levels affecting coastal cities',\n",
    "        'Stock market hits record high amid economic recovery',\n",
    "        'New study links processed foods to increased health risks',\n",
    "        'Sports team wins championship in dramatic final match',\n",
    "        'Breakthrough in renewable energy technology announced',\n",
    "        'Major corporation accused of environmental violations'\n",
    "    ],\n",
    "    'text': [\n",
    "        'The government has unveiled a series of new economic policies aimed at stimulating growth and increasing employment opportunities. Officials believe these measures will help stabilize the economy.',\n",
    "        'A group of scientists has identified a previously unknown species of amphibians deep in the Amazon rainforest, shedding light on the region’s incredible biodiversity and ecological significance.',\n",
    "        'A large-scale cyberattack has disrupted banking operations across multiple European countries, causing financial institutions to implement emergency security measures to protect customer data.',\n",
    "        'A world-renowned actor has pledged a significant portion of their wealth to support climate change research initiatives, aiming to fund projects that seek solutions to environmental issues.',\n",
    "        'Climate scientists have issued a warning about the rising sea levels and their impact on major coastal cities, urging governments to take immediate action to prevent catastrophic consequences.',\n",
    "        'The stock market has reached an all-time high, fueled by strong corporate earnings and renewed investor confidence in the ongoing economic recovery, according to financial analysts.',\n",
    "        'A newly published study has found a correlation between the consumption of processed foods and increased health risks, leading to calls for better dietary regulations and awareness campaigns.',\n",
    "        'In an intense and thrilling final match, the underdog sports team secured a stunning victory, claiming the championship title and delighting fans around the world with their performance.',\n",
    "        'Scientists have announced a major breakthrough in renewable energy technology, which could significantly improve the efficiency of solar panels and make sustainable energy more accessible globally.',\n",
    "        'A well-known multinational corporation has come under fire after allegations surfaced about environmental violations, prompting an investigation into its practices and potential legal actions.'\n",
    "    ],\n",
    "    'lable': ['TRUE', 'TRUE', 'FAKE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'TRUE', 'FAKE'],\n",
    "})\n",
    "\n",
    "# Encode labels: FAKE -> 0, TRUE -> 1\n",
    "dataset1['lable'] = dataset1['lable'].map({'FAKE': 0, 'TRUE': 1})\n",
    "\n",
    "# Combine 'title' and 'text' columns to create a single text feature\n",
    "dataset1['combined_text'] = dataset1['title'] + \" \" + dataset1['text']\n",
    "\n",
    "# Initialize PorterStemmer for word stemming\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Tokenize and stem the combined text to reduce words to their root form\n",
    "dataset1['combined_text_tokens'] = dataset1['combined_text'].apply(word_tokenize)\n",
    "dataset1['combined_text_stemmed'] = dataset1['combined_text_tokens'].apply(lambda tokens: [ps.stem(token) for token in tokens])\n",
    "\n",
    "# Convert stemmed tokens back into strings for CountVectorizer\n",
    "dataset1['combined_text_stemmed_text'] = dataset1['combined_text_stemmed'].apply(' '.join)\n",
    "\n",
    "# Use CountVectorizer to convert text into a bag-of-words representation\n",
    "vectorizer = CountVectorizer()\n",
    "vector = vectorizer.fit_transform(dataset1['combined_text_stemmed_text'])\n",
    "dataset1['combined_text_encoded'] = vector.toarray().tolist()\n",
    "\n",
    "# Drop intermediate columns to clean up the DataFrame\n",
    "dataset1 = dataset1.drop(columns=['combined_text_tokens', 'combined_text_stemmed', 'combined_text_stemmed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.6666666666666666\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.00      0.00      0.00         1\n",
      "        TRUE       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.67         3\n",
      "   macro avg       0.33      0.50      0.40         3\n",
      "weighted avg       0.44      0.67      0.53         3\n",
      "\n",
      "Naive Bayes Accuracy: 0.3333333333333333\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.33      1.00      0.50         1\n",
      "        TRUE       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.17      0.50      0.25         3\n",
      "weighted avg       0.11      0.33      0.17         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxmi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\maxmi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\maxmi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\maxmi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\maxmi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\maxmi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Prepare feature matrix (X) and target vector (y) for model training\n",
    "X = dataset1['combined_text_encoded'].tolist()\n",
    "y = dataset1['lable']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=69)\n",
    "\n",
    "# Train and evaluate a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=69)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred, target_names=['FAKE', 'TRUE']))\n",
    "\n",
    "# Train and evaluate a Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Naive Bayes Classification Report:\\n\", classification_report(y_test, y_pred_nb, target_names=['FAKE', 'TRUE']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
